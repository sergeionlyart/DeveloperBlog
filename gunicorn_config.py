"""
Конфигурация Gunicorn для оптимизации производительности и устранения проблем с сигналами

Этот файл содержит настройки для оптимизации стабильности, обработки сигналов
и предотвращения зависаний под нагрузкой.
"""

import multiprocessing
import os
import resource

# Основные настройки сервера
bind = "0.0.0.0:5000"
workers = multiprocessing.cpu_count() * 2 + 1  # Рекомендуемое количество
worker_class = "sync"  # Синхронные воркеры для максимальной стабильности
timeout = 120  # Увеличенный тайм-аут для предотвращения преждевременного убийства процессов
capture_output = True  # Перехватывать вывод для улучшенного логирования

# Предотвращение проблем с сигналами
ignore_winch = True  # Игнорировать сигнал WINCH полностью
reuse_port = True  # Улучшает поведение при перезапуске

# Основные оптимизации производительности
max_requests = 1000  # Перезапускать воркеры после обработки 1000 запросов
max_requests_jitter = 200  # Добавить случайность для предотвращения одновременного перезапуска
graceful_timeout = 30  # Время ожидания до принудительного завершения
keepalive = 5  # Сохранять соединение в течение 5 секунд после запроса

# Логирование с улучшенной гибкостью
accesslog = "-"  # Выводить логи доступа в stdout
errorlog = "-"   # Выводить логи ошибок в stdout
loglevel = "info"
access_log_format = '%(h)s %(l)s %(u)s %(t)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s" %(L)s'
logger_class = 'gunicorn.glogging.Logger'

# Отладочные возможности
reload = True  # Перезагрузка при изменении файлов
spew = False  # Включать подробное логирование трассировки (в случае необходимости отладки установите True)

# Регулирование нагрузки для предотвращения перегрузки
worker_connections = 1000  # Максимальное количество соединений на воркер
limit_request_line = 4094  # Ограничение длины строки запроса для предотвращения атак
limit_request_fields = 100  # Ограничение количества заголовков для предотвращения атак
limit_request_field_size = 8190  # Ограничение размера заголовков

# Путь к приложению
wsgi_app = "main:app"

# Дополнительные функции для улучшения стабильности
def post_fork(server, worker):
    """Выполняется после создания рабочего процесса"""
    # Устанавливаем мягкий лимит для файловых дескрипторов
    try:
        soft, hard = resource.getrlimit(resource.RLIMIT_NOFILE)
        resource.setrlimit(resource.RLIMIT_NOFILE, (hard, hard))
    except (ValueError, resource.error):
        pass

def worker_int(worker):
    """Обработчик получения сигнала SIGINT"""
    # Ничего не делаем для предотвращения зависаний из-за несинхронизированного логирования
    pass

def worker_abort(worker):
    """Обработчик аварийного прерывания"""
    # Ничего не делаем для предотвращения зависаний из-за несинхронизированного логирования
    pass